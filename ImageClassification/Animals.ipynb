{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification using 4 animals Kaggle dataset\n",
    "\n",
    "View dataset description and leaderboard [here](https://www.kaggle.com/competitions/4-animal-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU compatibility\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    print(\"GPU device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU memory:\", round(torch.cuda.get_device_properties(0).total_memory/1024**3),\"GB\")\n",
    "else:\n",
    "    print(\"GPU is not available. Using CPU\")\n",
    "    \n",
    "CUDA = torch.cuda.is_available()\n",
    "device = \"cuda\" if CUDA else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "test_data =[]\n",
    "train_data_x = []\n",
    "train_data_y = []\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((244,244)),\n",
    "])\n",
    "\n",
    "for file in glob(\"./data/4-animal-classification/test/test/*\"):\n",
    "    img = Image.open(file)\n",
    "    img = transform(img)\n",
    "    test_data.append(img)\n",
    "    \n",
    "\n",
    "animals = ['cat','deer','dog','horse']\n",
    "\n",
    "for label, animal in enumerate(animals):\n",
    "    for file in glob(f\"./data/4-animal-classification/train/{animal}/*\"):\n",
    "        img = Image.open(file)\n",
    "        img = transform(img)\n",
    "        train_data_x.append(img)\n",
    "        train_data_y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "test_data = torch.tensor(np.array(test_data),dtype=torch.float32)\n",
    "train_data_x = torch.tensor(np.array(train_data_x),dtype=torch.float32)\n",
    "train_data_y = torch.tensor(np.array(train_data_y),dtype=torch.long)\n",
    "\n",
    "# one_hot encode labels\n",
    "train_data_y = nn.functional.one_hot(train_data_y,4)\n",
    "train_data_y = train_data_y.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data shape:\",train_data_x.shape)\n",
    "print(\"Train label shape:\",train_data_y.shape)\n",
    "print(\"Test data shape:\",test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data \n",
    "torch.save(train_data_x, \"./data/4-animal-classification/train_data_x.pt\")\n",
    "torch.save(train_data_y, \"./data/4-animal-classification/train_data_y.pt\")\n",
    "torch.save(test_data, \"./data/4-animal-classification/test_data.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.sequential_224 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_112 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_56 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_28 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_14 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512*7*7, out_features=2**12), nn.ReLU(),\n",
    "            nn.Linear(in_features=2**12, out_features=2**11), nn.ReLU(),\n",
    "            nn.Linear(in_features=2**11, out_features=num_classes), nn.ReLU(),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.sequential_224(x)\n",
    "        x = self.sequential_112(x)\n",
    "        x = self.sequential_56(x)\n",
    "        x = self.sequential_28(x)\n",
    "        x = self.sequential_14(x)\n",
    "        x = self.sequential_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load train data\n",
    "train_data_x = torch.load(\"./data/4-animal-classification/train_data_x.pt\",mmap=True)\n",
    "train_data_y = torch.load(\"./data/4-animal-classification/train_data_y.pt\",mmap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data loader\n",
    "batch_size = 6\n",
    "\n",
    "train_idx, val_idx = train_test_split(np.arange(train_data_x.shape[0]), test_size=0.25,shuffle=True,random_state=42)\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self,data,label,idx_list):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.idx_list = idx_list\n",
    "    def __len__(self):\n",
    "        return self.idx_list.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[self.idx_list[idx]], self.label[self.idx_list[idx]]\n",
    "\n",
    "\n",
    "train_data = Data(train_data_x,train_data_y,train_idx)\n",
    "val_data = Data(train_data_x,train_data_y,val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "val_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and otimizer\n",
    "model = VGG16(num_classes=4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "model = model.to(device)\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = 0 \n",
    "    val_loss = 0\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(val_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            val_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} | Train Loss: {train_loss} | Val Loss: {val_loss}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
