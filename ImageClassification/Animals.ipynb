{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification using 4 animals Kaggle dataset\n",
    "\n",
    "View dataset description and leaderboard [here](https://www.kaggle.com/competitions/4-animal-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU compatibility\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available\")\n",
    "    print(\"GPU device:\", torch.cuda.get_device_name(0))\n",
    "    print(\"GPU memory:\", round(torch.cuda.get_device_properties(0).total_memory/1024**3),\"GB\")\n",
    "else:\n",
    "    print(\"GPU is not available. Using CPU\")\n",
    "    \n",
    "CUDA = torch.cuda.is_available()\n",
    "device = \"cuda\" if CUDA else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load data\n",
    "test_data =[]\n",
    "train_data_x = []\n",
    "train_data_y = []\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "for file in glob(\"./data/4-animal-classification/test/test/*\"):\n",
    "    img = Image.open(file)\n",
    "    img = transform(img)\n",
    "    test_data.append(img)\n",
    "    \n",
    "\n",
    "animals = ['cat','deer','dog','horse']\n",
    "\n",
    "for label, animal in enumerate(animals):\n",
    "    for file in glob(f\"./data/4-animal-classification/train/{animal}/*\"):\n",
    "        img = Image.open(file)\n",
    "        img = transform(img)\n",
    "        train_data_x.append(img)\n",
    "        train_data_y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "test_data = torch.tensor(np.array(test_data),dtype=torch.float32)\n",
    "train_data_x = torch.tensor(np.array(train_data_x),dtype=torch.float32)\n",
    "train_data_y = torch.tensor(np.array(train_data_y),dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data shape:\",train_data_x.shape)\n",
    "print(\"Train label shape:\",train_data_y.shape)\n",
    "print(\"Test data shape:\",test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data \n",
    "torch.save(train_data_x, \"./data/4-animal-classification/train_data_x.pt\")\n",
    "torch.save(train_data_y, \"./data/4-animal-classification/train_data_y.pt\")\n",
    "torch.save(test_data, \"./data/4-animal-classification/test_data.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.sequential_224 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_112 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_56 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_28 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_14 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding='same'), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.sequential_linear = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512*7*7, out_features=2**13), nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2**13, out_features=2**12), nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2**12, out_features=2**11), nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2**11, out_features=2**10), nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=2**10, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.sequential_224(x)\n",
    "        x = self.sequential_112(x)\n",
    "        x = self.sequential_56(x)\n",
    "        x = self.sequential_28(x)\n",
    "        x = self.sequential_14(x)\n",
    "        x = self.sequential_linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load train data\n",
    "train_data_x = torch.load(\"./data/4-animal-classification/train_data_x.pt\")\n",
    "train_data_y = torch.load(\"./data/4-animal-classification/train_data_y.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data loader\n",
    "batch_size = 2\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_data_x,train_data_y, test_size=0.2, random_state=42)\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self,data,label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx], self.label[idx]\n",
    "\n",
    "\n",
    "train_data = Data(train_x,train_y)\n",
    "val_data = Data(val_x,val_y)\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
    "val_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = models.vgg16()\n",
    "# model.classifier[6] = nn.Linear(in_features=4096,out_features=4)\n",
    "# print(model.forward)\n",
    "model = VGG16(4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.003)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "min_val_loss=10000000\n",
    "for epoch in range(50):\n",
    "    total_loss_train=0\n",
    "    total_acc_train=0\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        output = model(x.float())\n",
    "        \n",
    "        \n",
    "        batch_loss = criterion(output, y)\n",
    "        total_loss_train += batch_loss.item()\n",
    "        \n",
    "        acc = (output.argmax(dim=1)==y).sum().item()\n",
    "        total_acc_train += acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss_val=0\n",
    "    total_acc_val=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(val_loader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            output = model(x.float())\n",
    "            batch_loss = criterion(output, y)\n",
    "            total_loss_val += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1)==y).sum().item()\n",
    "            total_acc_val += acc\n",
    "\n",
    "    print(\n",
    "        f'Epochs: {epoch+1} | Train Loss: {total_loss_train / len(train_x):.3f}\\\n",
    "        | Train Accuracy: {total_acc_train/len(train_x):.3f}\\\n",
    "        | Val Loss: {total_loss_val/len(val_x):.3f}\\\n",
    "        | Val Accuracy:{total_acc_val/len(val_x):.3f}'\n",
    "    )\n",
    "\n",
    "    if min_val_loss>total_loss_val/len(val_x):\n",
    "        min_val_loss = total_loss_val/len(val_x)\n",
    "        torch.save(model.state_dict(), \"simplemodel.pt\")\n",
    "        print(f\"Save model because val loss improve loss {min_val_loss:.3f}\")\n",
    "    \n",
    "    print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
